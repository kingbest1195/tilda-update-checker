"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É –≤–µ—Ä—Å–∏—è–º–∏ —Ñ–∞–π–ª–æ–≤ Tilda CDN
"""
import logging
import hashlib
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple

import requests

import config
from src.database import db, TrackedFile, FileVersion, VersionAlert
from src.version_detector import detector

logger = logging.getLogger(__name__)


# –ó–∞–¥–µ—Ä–∂–∫–∏ –º–∏–≥—Ä–∞—Ü–∏–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
MIGRATION_DELAYS = {
    "CRITICAL": 0,       # –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ
    "HIGH": 3600,        # –ß–µ—Ä–µ–∑ 1 —á–∞—Å
    "MEDIUM": 86400,     # –ß–µ—Ä–µ–∑ 24 —á–∞—Å–∞
    "LOW": 604800        # –ß–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é
}


class MigrationManager:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏—è–º–∏ –≤–µ—Ä—Å–∏–π —Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –º–∏–≥—Ä–∞—Ü–∏–π"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': config.USER_AGENT
        })
    
    def validate_new_version(self, url: str, timeout: int = 30) -> Tuple[bool, Optional[str], Optional[Dict]]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π
        
        Args:
            url: URL –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            Tuple (—É—Å–ø–µ—Ö, –æ—à–∏–±–∫–∞, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
            - —É—Å–ø–µ—Ö: True –µ—Å–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
            - –æ—à–∏–±–∫–∞: —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∏–ª–∏ None
            - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: —Å–ª–æ–≤–∞—Ä—å —Å content, hash, size –∏–ª–∏ None
        """
        start_time = time.time()
        
        try:
            logger.info(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞: {url}")
            
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
            response = self.session.get(url, timeout=timeout)
            
            if response.status_code == 404:
                return False, "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω (404)", None
            
            response.raise_for_status()
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            content = response.text
            
            if not content or len(content) < 10:
                return False, "–§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π", None
            
            # 3. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()
            size = len(content.encode('utf-8'))
            
            validation_time = time.time() - start_time
            
            metadata = {
                'content': content,
                'hash': content_hash,
                'size': size,
                'validation_time': validation_time
            }
            
            logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: {url} ({size} –±–∞–π—Ç, {validation_time:.2f}—Å)")
            return True, None, metadata
            
        except requests.exceptions.Timeout:
            return False, f"Timeout –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ ({timeout}s)", None
        except requests.exceptions.RequestException as e:
            return False, f"–û—à–∏–±–∫–∞ HTTP: {str(e)}", None
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ {url}: {e}", exc_info=True)
            return False, f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}", None
    
    def archive_old_version(self, tracked_file: TrackedFile) -> Optional[FileVersion]:
        """
        –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏ —Ñ–∞–π–ª–∞
        
        Args:
            tracked_file: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–π —Ñ–∞–π–ª –¥–ª—è –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            FileVersion –æ–±—ä–µ–∫—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            logger.info(f"–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏: {tracked_file.url}")
            
            # –ü–∞—Ä—Å–∏–Ω–≥ URL –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
            if not tracked_file.base_name:
                parsed = detector.parse_file_url(tracked_file.url)
                tracked_file.base_name = parsed['base_name']
                tracked_file.version = parsed['version']
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ FileVersion
            file_version = db.save_file_version(
                base_name=tracked_file.base_name,
                version=tracked_file.version or 'unknown',
                full_url=tracked_file.url,
                file_type=tracked_file.file_type,
                category=tracked_file.category,
                priority=tracked_file.priority,
                domain=tracked_file.domain,
                last_hash=tracked_file.last_hash,
                last_content=tracked_file.last_content,
                last_size=tracked_file.last_size,
                tracked_file_id=tracked_file.id
            )
            
            # –î–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏ –≤ TrackedFile
            session = db.get_session()
            try:
                tf = session.query(TrackedFile).filter(TrackedFile.id == tracked_file.id).first()
                if tf:
                    tf.is_active = 0
                    session.commit()
                    logger.info(f"‚úÖ –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∞: {tracked_file.base_name} v{tracked_file.version}")
            finally:
                session.close()
            
            return file_version
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏ {tracked_file.url}: {e}", exc_info=True)
            return None
    
    def activate_new_version(self, url: str, metadata: Dict, version_info: Dict) -> Optional[TrackedFile]:
        """
        –ê–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ —Ñ–∞–π–ª–∞
        
        Args:
            url: URL –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (content, hash, size)
            version_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ—Ä—Å–∏–∏ (base_name, version, category, priority, etc.)
            
        Returns:
            TrackedFile –æ–±—ä–µ–∫—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            logger.info(f"–ê–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏: {url}")
            
            # –ü–∞—Ä—Å–∏–Ω–≥ URL
            parsed = detector.parse_file_url(url)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ TrackedFile
            tracked_file = db.save_file_state(
                url=url,
                file_type=parsed['file_type'],
                content=metadata['content'],
                content_hash=metadata['hash'],
                size=metadata['size'],
                category=version_info.get('category', 'unknown'),
                priority=version_info.get('priority', 'MEDIUM'),
                domain=parsed['domain']
            )
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ base_name –∏ version
            session = db.get_session()
            try:
                tf = session.query(TrackedFile).filter(TrackedFile.id == tracked_file.id).first()
                if tf:
                    tf.base_name = version_info['base_name']
                    tf.version = version_info['new_version']
                    tf.is_active = 1
                    session.commit()
            finally:
                session.close()
            
            logger.info(
                f"‚úÖ –ù–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞: {version_info['base_name']} "
                f"v{version_info['new_version']}"
            )
            return tracked_file
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ {url}: {e}", exc_info=True)
            return None
    
    def perform_migration(self, update_info: Dict, force: bool = False) -> bool:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—É—é –º–∏–≥—Ä–∞—Ü–∏—é —Å –æ–¥–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –Ω–∞ –¥—Ä—É–≥—É—é
        
        Args:
            update_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ (–∏–∑ version_detector)
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è –±–µ–∑ —É—á–µ—Ç–∞ –∑–∞–¥–µ—Ä–∂–µ–∫
            
        Returns:
            True –µ—Å–ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        base_name = update_info['base_name']
        new_version = update_info['new_version']
        new_url = update_info['new_url']
        priority = update_info['priority']
        
        logger.info(f"\n{'='*80}")
        logger.info(f"üîÑ –ù–ê–ß–ê–õ–û –ú–ò–ì–†–ê–¶–ò–ò: {base_name} -> v{new_version}")
        logger.info(f"{'='*80}")
        
        migration_start = time.time()
        
        # –°–æ–∑–¥–∞—Ç—å –∞–ª–µ—Ä—Ç
        alert = db.create_version_alert(
            base_name=base_name,
            old_version=update_info.get('current_version'),
            new_version=new_version,
            old_url=update_info.get('current_url'),
            new_url=new_url,
            category=update_info.get('category'),
            priority=priority
        )
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–¥–µ—Ä–∂–∫–∏ (–µ—Å–ª–∏ –Ω–µ force)
            if not force:
                delay = MIGRATION_DELAYS.get(priority, 0)
                if delay > 0:
                    logger.info(f"‚è± –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–ª–æ–∂–µ–Ω–∞ –Ω–∞ {delay}—Å —Å–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É {priority}")
                    # TODO: –í production —ç—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ scheduler
                    # –ü–æ–∫–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –¥–ª—è MVP
                    pass
            
            # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
            logger.info("–®–∞–≥ 1/3: –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞...")
            is_valid, error, metadata = self.validate_new_version(new_url)
            
            if not is_valid:
                logger.error(f"‚ùå –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞: {error}")
                db.update_version_alert_status(alert.id, 'failed', error)
                return False
            
            # 2. –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏
            logger.info("–®–∞–≥ 2/3: –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏...")
            old_tracked_file = db.get_file_by_base_name(base_name)
            
            if old_tracked_file:
                archived = self.archive_old_version(old_tracked_file)
                if not archived:
                    logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏")
                    db.update_version_alert_status(alert.id, 'failed', 'Archive error')
                    return False
            else:
                logger.warning(f"‚ö†Ô∏è –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è {base_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ë–î (–≤–æ–∑–º–æ–∂–Ω–æ, –ø–µ—Ä–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è)")
            
            # 3. –ê–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏
            logger.info("–®–∞–≥ 3/3: –ê–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏...")
            new_tracked_file = self.activate_new_version(new_url, metadata, update_info)
            
            if not new_tracked_file:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏")
                db.update_version_alert_status(alert.id, 'failed', 'Activation error')
                # –ü–æ–ø—ã—Ç–∫–∞ rollback (–µ—Å–ª–∏ –±—ã–ª–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏—è)
                if old_tracked_file:
                    self._attempt_rollback(old_tracked_file)
                return False
            
            # –£—Å–ø–µ—à–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
            migration_time = time.time() - migration_start
            db.update_version_alert_status(alert.id, 'completed')
            
            logger.info(f"{'='*80}")
            logger.info(f"‚úÖ –ú–ò–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û")
            logger.info(f"   –§–∞–π–ª: {base_name}")
            logger.info(f"   –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è: {update_info.get('current_version')}")
            logger.info(f"   –ù–æ–≤–∞—è –≤–µ—Ä—Å–∏—è: {new_version}")
            logger.info(f"   –í—Ä–µ–º—è: {migration_time:.2f}—Å")
            logger.info(f"{'='*80}\n")
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
            self._save_migration_metrics(
                discovered=1,
                successful=1,
                avg_migration_time=migration_time,
                avg_validation_time=metadata['validation_time']
            )
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}", exc_info=True)
            db.update_version_alert_status(alert.id, 'failed', str(e))
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –æ –Ω–µ—É–¥–∞—á–µ
            self._save_migration_metrics(discovered=1, failed=1)
            
            return False
    
    def perform_batch_migration(self, updates: List[Dict], force: bool = False) -> Dict[str, int]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–∞–∫–µ—Ç–Ω—É—é –º–∏–≥—Ä–∞—Ü–∏—é –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
        
        Args:
            updates: –°–ø–∏—Å–æ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {'successful': N, 'failed': M, 'skipped': K}
        """
        stats = {'successful': 0, 'failed': 0, 'skipped': 0}
        
        logger.info(f"\n{'='*80}")
        logger.info(f"üîÑ –ü–ê–ö–ï–¢–ù–ê–Ø –ú–ò–ì–†–ê–¶–ò–Ø: {len(updates)} —Ñ–∞–π–ª–æ–≤")
        logger.info(f"{'='*80}\n")
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        priority_order = {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
        sorted_updates = sorted(
            updates,
            key=lambda x: priority_order.get(x.get('priority', 'MEDIUM'), 99)
        )
        
        for i, update in enumerate(sorted_updates, 1):
            logger.info(f"\n[{i}/{len(updates)}] –ú–∏–≥—Ä–∞—Ü–∏—è: {update['base_name']}")
            
            success = self.perform_migration(update, force=force)
            
            if success:
                stats['successful'] += 1
            else:
                stats['failed'] += 1
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –º–∏–≥—Ä–∞—Ü–∏—è–º–∏
            if i < len(sorted_updates):
                time.sleep(2)
        
        logger.info(f"\n{'='*80}")
        logger.info(f"üìä –ò–¢–û–ì–ò –ü–ê–ö–ï–¢–ù–û–ô –ú–ò–ì–†–ê–¶–ò–ò")
        logger.info(f"{'='*80}")
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {stats['successful']}")
        logger.info(f"‚ùå –ù–µ—É–¥–∞—á–Ω–æ: {stats['failed']}")
        logger.info(f"‚è≠ –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
        logger.info(f"{'='*80}\n")
        
        return stats
    
    def rollback_to_version(self, base_name: str, version: str) -> bool:
        """
        –û—Ç–∫–∞—Ç–∏—Ç—å —Ñ–∞–π–ª –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏
        
        Args:
            base_name: –ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            version: –í–µ—Ä—Å–∏—è –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
            
        Returns:
            True –µ—Å–ª–∏ –æ—Ç–∫–∞—Ç —É—Å–ø–µ—à–µ–Ω
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"üîô –û–¢–ö–ê–¢: {base_name} -> v{version}")
        logger.info(f"{'='*80}")
        
        try:
            # –ù–∞–π—Ç–∏ –Ω—É–∂–Ω—É—é –≤–µ—Ä—Å–∏—é –≤ –∞—Ä—Ö–∏–≤–µ
            archived_version = db.get_version_by_exact(base_name, version)
            
            if not archived_version:
                logger.error(f"‚ùå –í–µ—Ä—Å–∏—è {base_name} v{version} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∞—Ä—Ö–∏–≤–µ")
                return False
            
            # –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∞–∫—Ç–∏–≤–Ω—É—é –≤–µ—Ä—Å–∏—é
            current_tracked = db.get_file_by_base_name(base_name)
            
            if current_tracked:
                # –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é
                logger.info("–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏...")
                self.archive_old_version(current_tracked)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—Ä—Ö–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å —É–∂–µ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
            logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∞—Ä—Ö–∏–≤–Ω–æ–π –≤–µ—Ä—Å–∏–∏...")
            is_valid, error, metadata = self.validate_new_version(archived_version.full_url)
            
            if not is_valid:
                # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä—Ö–∏–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ")
                if not archived_version.last_content:
                    logger.error("‚ùå –ê—Ä—Ö–∏–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
                    return False
                
                metadata = {
                    'content': archived_version.last_content,
                    'hash': archived_version.last_hash,
                    'size': archived_version.last_size,
                    'validation_time': 0
                }
            
            # –ê–∫—Ç–∏–≤–∞—Ü–∏—è –∞—Ä—Ö–∏–≤–Ω–æ–π –≤–µ—Ä—Å–∏–∏
            logger.info("–ê–∫—Ç–∏–≤–∞—Ü–∏—è –∞—Ä—Ö–∏–≤–Ω–æ–π –≤–µ—Ä—Å–∏–∏...")
            version_info = {
                'base_name': base_name,
                'new_version': version,
                'category': archived_version.category,
                'priority': archived_version.priority
            }
            
            restored = self.activate_new_version(
                archived_version.full_url,
                metadata,
                version_info
            )
            
            if not restored:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∞—Ä—Ö–∏–≤–Ω–æ–π –≤–µ—Ä—Å–∏–∏")
                return False
            
            # –°–æ–∑–¥–∞—Ç—å –∞–ª–µ—Ä—Ç –æ–± –æ—Ç–∫–∞—Ç–µ
            if current_tracked:
                alert = db.create_version_alert(
                    base_name=base_name,
                    old_version=current_tracked.version,
                    new_version=version,
                    old_url=current_tracked.url,
                    new_url=archived_version.full_url,
                    category=archived_version.category,
                    priority=archived_version.priority
                )
                db.update_version_alert_status(alert.id, 'rolled_back')
            
            logger.info(f"{'='*80}")
            logger.info(f"‚úÖ –û–¢–ö–ê–¢ –í–´–ü–û–õ–ù–ï–ù –£–°–ü–ï–®–ù–û")
            logger.info(f"   –§–∞–π–ª: {base_name}")
            logger.info(f"   –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤–µ—Ä—Å–∏—è: {version}")
            logger.info(f"{'='*80}\n")
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
            self._save_migration_metrics(rollbacks=1)
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–∞—Ç–µ: {e}", exc_info=True)
            return False
    
    def _attempt_rollback(self, old_tracked_file: TrackedFile):
        """–ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–∫–∞—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        try:
            logger.warning("‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–∫–∞—Ç–∞...")
            session = db.get_session()
            try:
                tf = session.query(TrackedFile).filter(TrackedFile.id == old_tracked_file.id).first()
                if tf:
                    tf.is_active = 1
                    session.commit()
                    logger.info("‚úÖ –û—Ç–∫–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω: —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            finally:
                session.close()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º –æ—Ç–∫–∞—Ç–µ: {e}")
    
    def _save_migration_metrics(self, discovered: int = 0, successful: int = 0,
                               failed: int = 0, rollbacks: int = 0,
                               avg_migration_time: float = None,
                               avg_validation_time: float = None):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        try:
            db.save_migration_metrics(
                discovered=discovered,
                successful=successful,
                failed=failed,
                rollbacks=rollbacks,
                avg_migration_time=avg_migration_time,
                avg_validation_time=avg_validation_time
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {e}")
    
    def get_migration_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –º–∏–≥—Ä–∞—Ü–∏–π
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –º–∏–≥—Ä–∞—Ü–∏–π
        """
        try:
            pending_alerts = db.get_pending_alerts()
            recent_alerts = db.get_recent_version_alerts(limit=20)
            metrics = db.get_metrics_summary(days=30)
            
            return {
                'pending_migrations': len(pending_alerts),
                'recent_migrations': len([a for a in recent_alerts if a.migration_status == 'completed']),
                'failed_migrations': len([a for a in recent_alerts if a.migration_status == 'failed']),
                'metrics_30d': metrics
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –º–∏–≥—Ä–∞—Ü–∏–π: {e}")
            return {}


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –º–∏–≥—Ä–∞—Ü–∏–π
manager = MigrationManager()



