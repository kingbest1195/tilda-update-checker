"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π —Ñ–∞–π–ª–æ–≤ Tilda CDN
"""
import logging
import re
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse
from packaging import version as pkg_version

from src.database import db, TrackedFile, DiscoveredFile

logger = logging.getLogger(__name__)


class VersionDetector:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π —Ñ–∞–π–ª–æ–≤"""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π –∏–∑ URL
    VERSION_PATTERNS = [
        # tilda-cart-1.1.min.js
        r'(?P<base>[\w-]+)-(?P<version>\d+\.\d+(?:\.\d+)?)(\.min)?\.(?P<ext>js|css)',
        # tilda-cart-v2.min.js
        r'(?P<base>[\w-]+)-v(?P<version>\d+(?:\.\d+)*)(\.min)?\.(?P<ext>js|css)',
        # tilda-cart.1.0.min.js (–º–µ–Ω–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ)
        r'(?P<base>[\w-]+)\.(?P<version>\d+\.\d+(?:\.\d+)?)(\.min)?\.(?P<ext>js|css)',
        # –ë–µ–∑ –≤–µ—Ä—Å–∏–∏: tilda-cart.min.js
        r'(?P<base>[\w-]+)(\.min)?\.(?P<ext>js|css)$',
    ]
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –≤–µ—Ä—Å–∏–π"""
        pass
    
    def parse_file_url(self, url: str) -> Dict[str, Optional[str]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ URL –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∏–º–µ–Ω–∏ –∏ –≤–µ—Ä—Å–∏–∏
        
        Args:
            url: URL —Ñ–∞–π–ª–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏: base_name, version, file_type, domain, full_url
        """
        parsed_url = urlparse(url)
        domain = parsed_url.netloc
        path = parsed_url.path
        filename = path.split('/')[-1]
        
        result = {
            'base_name': None,
            'version': None,
            'file_type': None,
            'domain': domain,
            'full_url': url,
            'filename': filename
        }
        
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in self.VERSION_PATTERNS:
            match = re.search(pattern, filename)
            if match:
                groups = match.groupdict()
                result['base_name'] = groups.get('base')
                result['version'] = groups.get('version', None)
                result['file_type'] = groups.get('ext')
                
                logger.debug(f"Parsed {filename}: base='{result['base_name']}', version='{result['version']}'")
                return result
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ–≤–ø–∞–ª–æ, –ø–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Ö–æ—Ç—è –±—ã –±–∞–∑–æ–≤–æ–µ –∏–º—è
        if filename.endswith('.js'):
            result['base_name'] = filename.replace('.min.js', '').replace('.js', '')
            result['file_type'] = 'js'
        elif filename.endswith('.css'):
            result['base_name'] = filename.replace('.min.css', '').replace('.css', '')
            result['file_type'] = 'css'
        
        logger.debug(f"Fallback parse for {filename}: base='{result['base_name']}', no version")
        return result
    
    def compare_versions(self, version1: str, version2: str) -> int:
        """
        –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π
        
        Args:
            version1: –ü–µ—Ä–≤–∞—è –≤–µ—Ä—Å–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1.0")
            version2: –í—Ç–æ—Ä–∞—è –≤–µ—Ä—Å–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1.1")
            
        Returns:
            -1 –µ—Å–ª–∏ version1 < version2
             0 –µ—Å–ª–∏ version1 == version2
             1 –µ—Å–ª–∏ version1 > version2
        """
        if version1 is None and version2 is None:
            return 0
        if version1 is None:
            return -1
        if version2 is None:
            return 1
        
        try:
            v1 = pkg_version.parse(version1)
            v2 = pkg_version.parse(version2)
            
            if v1 < v2:
                return -1
            elif v1 > v2:
                return 1
            else:
                return 0
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –≤–µ—Ä—Å–∏–π '{version1}' –∏ '{version2}': {e}")
            # Fallback –Ω–∞ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            if version1 < version2:
                return -1
            elif version1 > version2:
                return 1
            else:
                return 0
    
    def is_newer_version(self, current_version: str, new_version: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ new_version –Ω–æ–≤–µ–µ current_version
        
        Args:
            current_version: –¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è
            new_version: –ù–æ–≤–∞—è –≤–µ—Ä—Å–∏—è
            
        Returns:
            True –µ—Å–ª–∏ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–æ–≤–µ–µ
        """
        return self.compare_versions(current_version, new_version) == -1
    
    def find_version_updates(self, tracked_files: List[TrackedFile],
                           discovered_files: List[DiscoveredFile]) -> List[Dict]:
        """
        –ù–∞–π—Ç–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π, —Å—Ä–∞–≤–Ω–∏–≤–∞—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        
        Args:
            tracked_files: –°–ø–∏—Å–æ–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
            discovered_files: –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è—Ö:
            - base_name
            - current_version
            - current_url
            - new_version
            - new_url
            - priority
            - category
        """
        updates = []
        
        # –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ base_name
        tracked_index = {}
        for tf in tracked_files:
            if not tf.base_name:
                # –ï—Å–ª–∏ base_name –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ, –ø–∞—Ä—Å–∏–º URL
                parsed = self.parse_file_url(tf.url)
                tf.base_name = parsed['base_name']
            
            if tf.base_name and tf.is_active:
                tracked_index[tf.base_name] = tf
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π
        for df in discovered_files:
            parsed = self.parse_file_url(df.url)
            base_name = parsed['base_name']
            new_version = parsed['version']
            
            if not base_name:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ—Ç —Ñ–∞–π–ª –≤ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö
            if base_name in tracked_index:
                tracked_file = tracked_index[base_name]
                current_version = tracked_file.version
                
                # –ï—Å–ª–∏ —É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –µ—Å—Ç—å –≤–µ—Ä—Å–∏—è –∏ –æ–Ω–∞ –Ω–æ–≤–µ–µ
                if new_version and self.is_newer_version(current_version, new_version):
                    updates.append({
                        'base_name': base_name,
                        'current_version': current_version or 'unknown',
                        'current_url': tracked_file.url,
                        'new_version': new_version,
                        'new_url': df.url,
                        'priority': tracked_file.priority,
                        'category': tracked_file.category,
                        'file_type': parsed['file_type'],
                        'domain': parsed['domain']
                    })
                    
                    logger.info(
                        f"üÜï –ù–∞–π–¥–µ–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {base_name} "
                        f"{current_version or 'unknown'} -> {new_version}"
                    )
        
        return updates
    
    def get_all_versions_for_base(self, base_name: str) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≤–µ—Ä—Å–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–∞–∫—Ç–∏–≤–Ω—ã–µ –∏ –∞—Ä—Ö–∏–≤–Ω—ã–µ)
        
        Args:
            base_name: –ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–µ—Ä—Å–∏—è—Ö
        """
        versions = []
        
        # –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é –≤–µ—Ä—Å–∏—é –∏–∑ TrackedFile
        tracked_file = db.get_file_by_base_name(base_name)
        if tracked_file:
            versions.append({
                'base_name': base_name,
                'version': tracked_file.version or 'unknown',
                'url': tracked_file.url,
                'is_active': True,
                'category': tracked_file.category,
                'priority': tracked_file.priority,
                'last_checked': tracked_file.last_checked
            })
        
        # –ü–æ–ª—É—á–∏—Ç—å –∞—Ä—Ö–∏–≤–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –∏–∑ FileVersion
        archived_versions = db.get_versions_by_base_name(base_name)
        for av in archived_versions:
            versions.append({
                'base_name': base_name,
                'version': av.version,
                'url': av.full_url,
                'is_active': False,
                'category': av.category,
                'priority': av.priority,
                'archived_at': av.archived_at
            })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤–µ—Ä—Å–∏–∏ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
        versions.sort(
            key=lambda x: pkg_version.parse(x['version']) if x['version'] != 'unknown' else pkg_version.parse('0.0'),
            reverse=True
        )
        
        return versions
    
    def detect_schema_change(self, old_url: str, new_url: str) -> Optional[str]:
        """
        –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ö–µ–º—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        
        Args:
            old_url: –°—Ç–∞—Ä—ã–π URL
            new_url: –ù–æ–≤—ã–π URL
            
        Returns:
            –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏–ª–∏ None
        """
        old_parsed = self.parse_file_url(old_url)
        new_parsed = self.parse_file_url(new_url)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ª–∏ –±–∞–∑–æ–≤–æ–µ –∏–º—è
        if old_parsed['base_name'] != new_parsed['base_name']:
            # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–∂–µ—Å—Ç—å (–ø—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞)
            similarity = self._calculate_similarity(
                old_parsed['base_name'],
                new_parsed['base_name']
            )
            
            if similarity > 0.7:  # –í—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
                return (
                    f"–í–æ–∑–º–æ–∂–Ω–∞ —Å–º–µ–Ω–∞ —Å—Ö–µ–º—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: "
                    f"{old_parsed['base_name']} -> {new_parsed['base_name']} "
                    f"(—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.0%})"
                )
        
        return None
    
    def _calculate_similarity(self, str1: str, str2: str) -> float:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å –ø—Ä–æ—Å—Ç—É—é –º–µ—Ç—Ä–∏–∫—É —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫ (Levenshtein-–ø–æ–¥–æ–±–Ω–∞—è)
        
        Args:
            str1: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞
            str2: –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞
            
        Returns:
            –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1
        """
        if not str1 or not str2:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—â–∏—Ö –ø–æ–¥—Å—Ç—Ä–æ–∫
        longer = str1 if len(str1) >= len(str2) else str2
        shorter = str2 if len(str1) >= len(str2) else str1
        
        # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –æ–±—â–∏–µ —Å–∏–º–≤–æ–ª—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        matches = 0
        j = 0
        for i, char in enumerate(shorter):
            if j < len(longer) and char == longer[j]:
                matches += 1
                j += 1
        
        return matches / len(longer)
    
    def analyze_discovered_files(self) -> Dict[str, List]:
        """
        –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –ø–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
            - version_updates: —Ñ–∞–π–ª—ã —Å –Ω–æ–≤—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏
            - new_files: —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã
            - schema_changes: —Ñ–∞–π–ª—ã —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏ —Å—Ö–µ–º—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
        """
        tracked_files = db.get_active_tracked_files()
        discovered_files = db.get_undiscovered_files()
        
        version_updates = self.find_version_updates(tracked_files, discovered_files)
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã (–Ω–µ –∏–º–µ—é—â–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –≤ tracked)
        tracked_base_names = {tf.base_name for tf in tracked_files if tf.base_name}
        
        new_files = []
        for df in discovered_files:
            parsed = self.parse_file_url(df.url)
            base_name = parsed['base_name']
            
            if base_name and base_name not in tracked_base_names:
                new_files.append({
                    'base_name': base_name,
                    'version': parsed['version'] or 'unknown',
                    'url': df.url,
                    'suggested_category': df.suggested_category,
                    'source_page': df.source_page
                })
        
        # –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å—Ö–µ–º—ã (—Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–∏)
        schema_changes = []
        # TODO: —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        
        return {
            'version_updates': version_updates,
            'new_files': new_files,
            'schema_changes': schema_changes
        }
    
    def print_version_updates_report(self, updates: List[Dict]):
        """–í—ã–≤–µ—Å—Ç–∏ –æ—Ç—á–µ—Ç –æ–± –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è—Ö –≤–µ—Ä—Å–∏–π"""
        if not updates:
            logger.info("üì≠ –û–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤–µ—Ä—Å–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            return
        
        logger.info(f"\n{'='*80}")
        logger.info(f"üìã –û–¢–ß–ï–¢ –û–ë –û–ë–ù–û–í–õ–ï–ù–ò–Ø–• –í–ï–†–°–ò–ô")
        logger.info(f"{'='*80}")
        logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π: {len(updates)}\n")
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        by_category = {}
        for update in updates:
            cat = update['category']
            if cat not in by_category:
                by_category[cat] = []
            by_category[cat].append(update)
        
        # –í—ã–≤–µ—Å—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
        priority_order = {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
        sorted_categories = sorted(
            by_category.items(),
            key=lambda x: priority_order.get(updates[0]['priority'], 99)
        )
        
        for category, cat_updates in sorted_categories:
            priority = cat_updates[0]['priority']
            logger.info(f"üìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category} (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}) - {len(cat_updates)} –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π")
            
            for update in cat_updates:
                logger.info(f"   üÜï {update['base_name']}")
                logger.info(f"      –¢–µ–∫—É—â–∞—è: {update['current_version']}")
                logger.info(f"      –ù–æ–≤–∞—è: {update['new_version']} ‚ú®")
                logger.info(f"      URL: {update['new_url']}")
            logger.info("")
        
        logger.info(f"{'='*80}\n")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
detector = VersionDetector()



